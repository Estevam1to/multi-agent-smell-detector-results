# ğŸ“Š Multi-Agent Code Smell Detector - Resultados

> **Trabalho de ConclusÃ£o de Curso (TCC)** - Sistema Multi-Agentes para DetecÃ§Ã£o de Code Smells em Python usando LLMs

## ğŸ“Œ Sobre

Este repositÃ³rio contÃ©m os **resultados e anÃ¡lises** do projeto de detecÃ§Ã£o de code smells usando sistema multi-agente baseado em LLM. O cÃ³digo-fonte da API estÃ¡ em um repositÃ³rio separado.

### ğŸ¯ Objetivo do Projeto

Desenvolver um sistema baseado em LLM multi-agente capaz de detectar 11 tipos de code smells em cÃ³digo Python com alta precisÃ£o, combinando anÃ¡lise estÃ¡tica e inteligÃªncia artificial.

## ğŸ“ˆ Resultados Principais

### Performance Geral (Melhor Modelo: Claude Sonnet 4.5)

| MÃ©trica | Prompts Elaborados | Prompts Simples |
|---------|-------------------|------------------|
| **F1-Score** | **61.62%** | 57.29% |
| **Precision** | 49.14% | 44.72% |
| **Recall** | 82.61% | 79.71% |
| **TP** | 57 | - |
| **FP** | 59 | - |
| **FN** | 12 | - |

### ComparaÃ§Ã£o entre Modelos LLM

| Modelo | F1-Score | Precision | Recall | Custo Total | Tempo |
|--------|----------|-----------|--------|-------------|-------|
| **Claude Sonnet 4.5** | 61.62% | 49.14% | 82.61% | $5.79 | 3.2 min |
| **GPT-4o-mini** | 65.12% | 54.37% | 81.16% | $0.21 | 2.5 min |
| **DeepSeek V3.2** | 62.30% | 71.70% | 55.07% | $0.30 | 7.6 min |

### Melhor Custo-BenefÃ­cio

**GPT-4o-mini** apresentou o melhor custo-benefÃ­cio com F1/$1 = **306.0** (vs Claude: 10.6, DeepSeek: 206.5)

## ğŸ”¬ Research Questions

| RQ | Pergunta | Resultado |
|----|----------|----------|
| **RQ1** | Qual a eficÃ¡cia do sistema multi-agentes? | F1=61.62% com Claude Sonnet 4.5 |
| **RQ2** | Impacto dos prompts na performance? | Elaborados +4.33pp vs Simples |
| **RQ3** | ComparaÃ§Ã£o entre LLMs? | GPT melhor F1 (65.1%), DeepSeek melhor Precision (71.7%) |
| **RQ4** | Performance por agente? | Claude e GPT empatados (5 agentes cada melhor) |
| **RQ5** | Custo-benefÃ­cio operacional? | GPT-4o-mini melhor (F1/$1=306.0) |

## ğŸ¤– Code Smells Detectados (11 tipos)

| # | Code Smell | Categoria | Threshold |
|---|------------|-----------|------------|
| 1 | **Long Method** | Complexidade | > 67 linhas |
| 2 | **Complex Method** | Complexidade | CC > 7 |
| 3 | **Complex Conditional** | Complexidade | > 2 operadores |
| 4 | **Long Parameter List** | Estrutura | > 4 parÃ¢metros |
| 5 | **Long Message Chain** | Estrutura | > 2 mÃ©todos |
| 6 | **Long Statement** | Statements | > 120 caracteres |
| 7 | **Long Identifier** | Nomenclatura | > 20 caracteres |
| 8 | **Magic Number** | Nomenclatura | Literais (exceto 0,1,-1) |
| 9 | **Empty Catch Block** | Statements | Bloco vazio |
| 10 | **Missing Default** | Statements | Sem case _ |
| 11 | **Long Lambda** | Statements | > 80 caracteres |

## ğŸ“ Estrutura do RepositÃ³rio

```
multi-agent-smell-detector-results/
â”œâ”€â”€ README.md
â”œâ”€â”€ ground_truth/
â”‚   â””â”€â”€ implementation_smells_manual_filtered.csv    # 411 smells validados
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ anthropic/
â”‚   â”‚   â””â”€â”€ claude-sonnet-4.5/
â”‚   â”‚       â”œâ”€â”€ results_complete_prompts.json        # DetecÃ§Ãµes (prompts elaborados)
â”‚   â”‚       â”œâ”€â”€ results_simple_prompt.csv            # DetecÃ§Ãµes (prompts simples)
â”‚   â”‚       â”œâ”€â”€ results_with_complete_prompts.csv    # CSV formatado
â”‚   â”‚       â”œâ”€â”€ token_usage_complete_prompts.json    # Uso de tokens e custos
â”‚   â”‚       â””â”€â”€ file_metrics_complete_prompts.json   # MÃ©tricas por arquivo
â”‚   â”‚
â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â””â”€â”€ gpt-4o-mini/
â”‚   â”‚       â”œâ”€â”€ results_complete_prompts.json
â”‚   â”‚       â”œâ”€â”€ token_usage_complete_prompts.json
â”‚   â”‚       â””â”€â”€ file_metrics_complete_prompts.json
â”‚   â”‚
â”‚   â””â”€â”€ deepseek/
â”‚       â””â”€â”€ deepseek-v3.2/
â”‚           â”œâ”€â”€ results_complete_prompts.json
â”‚           â”œâ”€â”€ token_usage_complete_prompts.json
â”‚           â””â”€â”€ file_metrics_complete_prompts.json
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ fig1_llm_comparison.png
â”‚   â”œâ”€â”€ fig2_f1_by_smell_comparison.png
â”‚   â”œâ”€â”€ fig3_cost_analysis.png
â”‚   â”œâ”€â”€ fig4_prompt_impact.png
â”‚   â””â”€â”€ fig5_efficiency_analysis.png
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ research_questions_analysis.ipynb           # AnÃ¡lise completa das RQs
â”‚
â””â”€â”€ docs/
    â””â”€â”€ smells.md                                   # DefiniÃ§Ãµes dos code smells
```

## ğŸ“Š Figuras

### Fig. 1 - ComparaÃ§Ã£o entre Modelos LLM
![LLM Comparison](figures/fig1_llm_comparison.png)

### Fig. 2 - F1-Score por Code Smell
![F1 by Smell](figures/fig2_f1_by_smell_comparison.png)

### Fig. 4 - Impacto dos Prompts
![Prompt Impact](figures/fig4_prompt_impact.png)

### Fig. 5 - AnÃ¡lise de EficiÃªncia
![Efficiency Analysis](figures/fig5_efficiency_analysis.png)

## ğŸ“š Dataset Analisado

| Projeto | DescriÃ§Ã£o | Arquivos |
|---------|-----------|----------|
| **codespell** | Spell checker para cÃ³digo | 4 |
| **maltrail** | Sistema de detecÃ§Ã£o de trÃ¡fego malicioso | 10 |
| **mava** | Framework para Multi-Agent RL | 6 |
| **Total** | | **20 arquivos** |

**Ground Truth:** 411 code smells validados manualmente em 19 mÃ³dulos

## ğŸ”— Links

- **RepositÃ³rio da API:** [multi-agent-smell-detector](https://github.com/Estevam1to/multi-agent-smell-detector)
- **Paper/TCC:** Em desenvolvimento

## ğŸ“– ReferÃªncias

1. **Fowler, M.** (1999, 2018). *Refactoring: Improving the Design of Existing Code*
2. **Martin, R. C.** (2008). *Clean Code: A Handbook of Agile Software Craftsmanship*
3. **McCabe, T. J.** (1976). "A Complexity Measure". *IEEE Transactions on Software Engineering*
4. **Chen et al.** (2016). "Detecting Code Smells in Python Programs". *SATE Conference*
5. **MITRE Corporation.** CWE-478: Missing Default Case

## ğŸ‘¨â€ğŸ’» Autor

**LuÃ­s Estevam Rosa Chaves**  
Engenharia de Software - Universidade Federal do CearÃ¡  
TCC - 2024/2025

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte de um Trabalho de ConclusÃ£o de Curso (TCC) acadÃªmico.